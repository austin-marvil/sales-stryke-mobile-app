"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.s3UploadFile = s3UploadFile;
const tslib_1 = require("tslib");
const axios_1 = require("axios");
const data_1 = require("../../data");
const client_1 = require("../../client");
const persistable_1 = require("../../entity/classes/persistable");
/**
 * UploadFile
 * @param {object} {file: FileList,} - See type of endpoint param
 */
function s3UploadFile(_a) {
    return tslib_1.__awaiter(this, arguments, void 0, function* ({ file, importDataMap, onProgress, onFailed, loader }) {
        var _b;
        const fileForm = new FormData();
        let IDF_Entity = new persistable_1.ImportDataFileUpload();
        IDF_Entity.setImportDataMap(importDataMap, data_1.PersistenceType.ATTACH);
        IDF_Entity.setFileName(file.name);
        IDF_Entity.setName(file.name);
        IDF_Entity.setImportStatus("Uploading");
        IDF_Entity = yield client_1.salesStrykeClientApiInstance.importDataFileUpload.getUploadPresignUrl(IDF_Entity);
        if (!IDF_Entity) {
            throw new Error("No Response");
        }
        let fileName = IDF_Entity.getFileName();
        let presignedS3Url = IDF_Entity.getPresignedUrl();
        if (!presignedS3Url || !fileName) {
            throw new Error("No presigned s3 URL or file name");
        }
        /*
            We do not need to set these field, our api from the response should already handle it.
                IDF_Entity.setFileName
                IDF_Entity.setOrganization
                IDF_Entity.setS3BucketName
                IDF_Entity.setPresignedUrl
            Only thing need to do is change the file name that is being upload
            Due to presigned URL expecting that file name / file type
        */
        // upload file name
        fileForm.append('file', file, fileName);
        try {
            const response = yield axios_1.default.put(presignedS3Url, file, {
                headers: {
                    'Content-Type': 'text/csv',
                },
                onUploadProgress: (progressEvent) => {
                    if (!progressEvent.total)
                        throw "error";
                    const percentCompleted = Math.round((progressEvent.loaded * 100) / progressEvent.total);
                    if (onProgress)
                        onProgress(percentCompleted); // Invoke the callback with the current progress
                },
            });
            if (onProgress)
                onProgress(100);
            // TODO status for Import Data File Upload
            // IDF_Entity.setStatus
            IDF_Entity.setImportStatus("Uploaded");
            let IDFU = yield client_1.salesStrykeClientApiInstance.importDataFileUpload.save(IDF_Entity);
            return IDFU;
            // once importdataFileUpload is successful we now need to run our post-upload logic
            // we would need to process the uploaded file into the desired format with our datamapper which is the importdatamap
            // we need to read the file from the s3 bucket
            // import data map would tell us how to transform the uploaded data into import data, which is our importData entity
        }
        catch (error) {
            console.error('Error uploading file:', (_b = error === null || error === void 0 ? void 0 : error.response) === null || _b === void 0 ? void 0 : _b.data);
            // input failer snackbar
            onFailed && onFailed();
            yield client_1.salesStrykeClientApiInstance.importDataFileUpload.delete(IDF_Entity);
            if (onProgress)
                onProgress(0);
        }
        return null;
    });
}
//# sourceMappingURL=Upload.function.js.map